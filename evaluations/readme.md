# Evaluations of RAM2C

- `manual_eval.py`: human volunteers manually evaluation.

- `IAA.py`: Inter-Annotator Agreement (IAA) calculation.

- `Q_A_eval.json`: 
    - the question-answer pairs used for evaluation.
    - 136 questions and 136 answers.

- `qwen`: the folder contains dialogues generated by Qwen model, and manual evaluation results.

    - `dpo_res_eval.json`: 
        - prompt and output.
        - prompt=question(1/136)+answer(1/136)+ref(1/3). 
        - output=response to the student. each Q-A pair has 3 responses.
        - so it contains 136*3=408 pairs.
        - by GLM-4 or GPT-4-turbo

    - `dpo_res_eval_expand.json`:
        - prompt and 3*output.
        - prompt=question(1/136)+answer(1/136)+ref(1/3). 
        - output=responses to the student. each Q-A pair has 3 responses.
        - 408 pairs.
        - by GLM-4 or GPT-4-turbo
        - cover the `dpo_res_eval.json`

    - `dpo_eval_res_qwen_dpo.txt`: 
        - positive samples by fine-tuned model
        - 408 resposnes.
        - by Qwen1.5-4B-Chat

    - `dpo_eval_res_qwen.txt`: 
        - negative samples by raw model
        - 408 responses.
        - by Qwen1.5-4B-Chat

    - `results`: the folder contains the manual evaluation results.